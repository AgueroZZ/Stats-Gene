% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Power of Wald test for interaction},
  pdfauthor={Ziang Zhang},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

\title{Power of Wald test for interaction}
\author{Ziang Zhang}
\date{09/03/2021}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\clearpage

\hypertarget{power-of-wald-test}{%
\section{Power of Wald test:}\label{power-of-wald-test}}

\hypertarget{for-one-parameter}{%
\subsection{For one parameter:}\label{for-one-parameter}}

If we consider using Wald test to test the null hypothesis
\(H_0:\theta=\theta_0\), the test statistic will be
\[\sqrt{\frac{n}{I^{-1}(\hat{\theta})}}\bigg(\hat{\theta} - \theta_0\bigg)\]
where \(\hat{\theta}\) is the MLE of \(\theta\) and
\(I^{-1}(\hat{\theta})\) is inverse of the fisher information evaluated
at the MLE.

Under null hypothesis, this test statistic follows a standard normal
distribution. If the alternative hypothesis
\(H_a:\theta=\theta_1 \neq \theta_0\), then the power of our test can be
computed as: \[1-\Phi(\Delta+z_{a/2}) + \Phi(\Delta-z_{a/2})\] where
\(\Delta = \sqrt{\frac{n}{I^{-1}(\hat{\theta})}}(\theta_0-\theta_1)\).

The important information above is that the power of Wald test will
depend on several things at the same time:

\begin{itemize}
\tightlist
\item
  The difference of \(\theta_0 - \theta_1\)
\item
  The sample size \(n\)
\item
  The \texttt{true} information's inverse \(I^{-1}(\theta_1)\)
\end{itemize}

In general, higher power is achieved when \(\Delta\) is large. That
implies, we have higher power if we have larger
\(|\theta_0 - \theta_1|\), \(n\) or smaller \(I^{-1}(\theta_1)\).

\hypertarget{general-expression-and-non-centrality-parameter}{%
\subsection{General Expression and Non-centrality
parameter:}\label{general-expression-and-non-centrality-parameter}}

In general for a vector of parameter \(\beta \in \mathbb{R}^p\), if we
are interested in testing the null hypothesis of linear combination of
\(\beta\): \(L\beta = 0\), then the test statistic will be
\[(L\hat{\beta})^T L{I_n^{-1}(\hat{\beta})L^T}(L\hat{\beta})\] which
follows a chi-square distribution with \(1\) degree of freedom under the
null hypothesis. The matrix \(I_n^{-1}(\hat{\beta})\) is the inverse of
the fisher information matrix of the whole sample, evaluated at
\(\beta = \hat{\beta}\).

Specifically, if we want to test the case where \(L =(0,0,..,1,0..,0)\),
then our test statistic reduced to
\[I_n^{-1}(\hat{\beta})_{[i,i]}(\hat{\beta}_i)^2\] where \(\beta_i\) is
the i-th component of \(\beta\), \(I_n^{-1}(\hat{{\beta}})_{[i,i]}\) is
the i-th diagonal term of \(I_n^{-1}(\hat{{\beta}})\). Under the
alternative hypothesis that \(\beta_i=\beta_{i1}\neq0\), the limiting
distribution will be a non-central chi-square distribution with
non-centrality parameter being \[I_n^{-1}(\beta)_{[i,i]}\beta_{i1}\]
here \(I_n^{-1}(\beta)\) is inverted fisher information matrix evaluated
at the true parameter vector \(\beta\).

Note that to compute \(I_n^{-1}(\beta)\), we may need more than just
\(\beta_{i1}\). Even though we are only interested in testing
\(\beta_i\), that does not imply we can compute \(I_n^{-1}(\beta)\) just
using the true value of \(\beta_i\). We will discuss this problem in the
next section in details.

\hypertarget{when-will-other-parameters-matter-for-our-power}{%
\section{When will other parameters matter for our
power?}\label{when-will-other-parameters-matter-for-our-power}}

\hypertarget{wald-test-for-lm}{%
\subsection{\texorpdfstring{Wald test for
\texttt{lm}:}{Wald test for lm:}}\label{wald-test-for-lm}}

To answer this question, we need to know when will \(I_n^{-1}(\beta)\)
depend on parameters other than \(\beta_i\). It turns out that if the
true underlying model of our data is a linear regression model,
\(I_n^{-1}(\beta)\) will not depend on any parameter. However, if the
true underlying model is not an ordinary linear regression model, but a
generalized linear regression model, then \(I_n^{-1}(\beta)\) will
depend on all the regression parameters.

If we consider the linear regression model:
\[y = \beta_0 + \beta_GG +\beta_EE+\beta_{GE}G\times E+\epsilon\] where
\(\epsilon \sim N(0,\sigma^2)\)

Then the fisher information matrix at \(\beta\) can be computed as
\[XX^T/\sigma^2\] Note that this matrix is only affected by the variance
parameter \(\sigma^2\), and not affected by any regression parameter
\(\beta\). Therefore, the power function of Wald test for
\(\beta_{GE}=0\) will only depend on the magnitude of the true value of
\(\beta_{GE}\).

\hypertarget{wald-test-for-glm}{%
\subsection{\texorpdfstring{Wald test for
\texttt{glm}:}{Wald test for glm:}}\label{wald-test-for-glm}}

On the other hand, if the true data generating model is
\[\mu = g^{-1}(\beta_0 + \beta_GG +\beta_EE+\beta_{GE}G\times E)\] where
\(g(.)\) is a specified link function connecting the linear predictor
with the mean of \(y\).

In this case, the information matrix can be written as \[XW(\beta)X^T\]
where the matrix \(W(\beta)\) is a diagonal matrix with each term
depends on all the regression parameter \(\beta\).

For a specific example, if we are using probit regression model, then
the matrix \(W(\beta)\) will be
\[W(\beta) = diag\bigg\{\frac{\phi^2(s_i)}{\Phi(s_i)(1-\Phi(s_i))}\bigg\}\]
where \(s_i = \beta_0 + \beta_GG_i +\beta_EE_i+\beta_{GE}G_i\times E_i\)
and \(\phi,\Phi\) are the density and cdf of standard normal
distribution respectively.

\clearpage

\hypertarget{computational-experiment}{%
\section{Computational Experiment:}\label{computational-experiment}}

Here we illustrate the phenomenon above using some computational
experiment, and compare the empirical power and the theoretical power:

\hypertarget{assume-data-generated-from-ordinary-linear-model}{%
\subsection{Assume data generated from ordinary linear
model}\label{assume-data-generated-from-ordinary-linear-model}}

In this section, we consider continuous trait generated from a linear
regression model:

First case, we consider the true \(\beta_{GE} = 0.1\) and true main
effect \(\beta_E=1\):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{N <-}\StringTok{ }\DecValTok{1000}
\NormalTok{G <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),}\DataTypeTok{size =}\NormalTok{ N, }\DataTypeTok{replace =}\NormalTok{ T, }\DataTypeTok{prob =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.16}\NormalTok{,}\FloatTok{0.48}\NormalTok{, }\FloatTok{0.36}\NormalTok{))}
\NormalTok{E <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}
\NormalTok{beta0 <-}\StringTok{ }\DecValTok{-1}
\NormalTok{betaG <-}\StringTok{ }\FloatTok{0.3}
\NormalTok{betaE <-}\StringTok{ }\DecValTok{1}
\NormalTok{betaGE <-}\StringTok{ }\FloatTok{0.1}
\NormalTok{ylat <-}\StringTok{ }\NormalTok{beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{betaG}\OperatorTok{*}\NormalTok{G }\OperatorTok{+}\StringTok{ }\NormalTok{betaE}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\NormalTok{betaGE}\OperatorTok{*}\NormalTok{G}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}

\NormalTok{mod <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(ylat}\OperatorTok{~}\NormalTok{G}\OperatorTok{+}\NormalTok{E}\OperatorTok{+}\KeywordTok{I}\NormalTok{(G}\OperatorTok{*}\NormalTok{E), }\DataTypeTok{family =} \KeywordTok{gaussian}\NormalTok{(}\DataTypeTok{link =} \StringTok{"identity"}\NormalTok{))}


\CommentTok{#### Get the design matrix:}
\NormalTok{X <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,N),mod}\OperatorTok{$}\NormalTok{model[,}\OperatorTok{-}\DecValTok{1}\NormalTok{])}

\CommentTok{### Compute the weight matrix W:}
\NormalTok{beta <-}\StringTok{ }\KeywordTok{c}\NormalTok{(beta0,betaG,betaE,betaGE)}



\CommentTok{### The true information matrix}
\NormalTok{I <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(}\KeywordTok{t}\NormalTok{(X)) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(X)}



\CommentTok{#### Invert to get the true covariance matrix }
\NormalTok{V <-}\StringTok{ }\KeywordTok{solve}\NormalTok{(I)}


\CommentTok{### Compute the power function }

\CommentTok{### Assume d = beta0 - beta1, where beta0 = 0 is what we are testing as null:}
\NormalTok{delta <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{V[}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{])}\OperatorTok{*}\NormalTok{(}\DecValTok{0}\OperatorTok{-}\NormalTok{beta[}\DecValTok{4}\NormalTok{])}
\NormalTok{alpha <-}\StringTok{ }\FloatTok{0.05}
\NormalTok{Power <-}\StringTok{ }\DecValTok{1}\OperatorTok{-}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(delta }\OperatorTok{-}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(alpha}\OperatorTok{/}\DecValTok{2}\NormalTok{)) }\OperatorTok{+}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(delta }\OperatorTok{+}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(alpha}\OperatorTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{Power}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6030156
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#### Illustrate that this power is correct:}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{p1 <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{1000}\NormalTok{) \{}
\NormalTok{  ylat <-}\StringTok{ }\NormalTok{beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{betaG}\OperatorTok{*}\NormalTok{G }\OperatorTok{+}\StringTok{ }\NormalTok{betaE}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\NormalTok{betaGE}\OperatorTok{*}\NormalTok{G}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}
\NormalTok{  mod <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(ylat}\OperatorTok{~}\NormalTok{G}\OperatorTok{+}\NormalTok{E}\OperatorTok{+}\KeywordTok{I}\NormalTok{(G}\OperatorTok{*}\NormalTok{E), }\DataTypeTok{family =} \KeywordTok{gaussian}\NormalTok{(}\DataTypeTok{link =} \StringTok{"identity"}\NormalTok{))}
\NormalTok{  p1[i] <-}\StringTok{ }\KeywordTok{summary}\NormalTok{(mod)}\OperatorTok{$}\NormalTok{coefficient[}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{]}
\NormalTok{\}}
\NormalTok{emp_power <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(p1 }\OperatorTok{<=}\StringTok{ }\NormalTok{alpha)}
\NormalTok{emp_power}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.575
\end{verbatim}

Second case, we consider the true \(\beta_{GE} = 0.1\) fixed but change
the true main effect \(\beta_E\) from 1 to 0:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{N <-}\StringTok{ }\DecValTok{1000}
\NormalTok{G <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),}\DataTypeTok{size =}\NormalTok{ N, }\DataTypeTok{replace =}\NormalTok{ T, }\DataTypeTok{prob =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.16}\NormalTok{,}\FloatTok{0.48}\NormalTok{, }\FloatTok{0.36}\NormalTok{))}
\NormalTok{E <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}
\NormalTok{beta0 <-}\StringTok{ }\DecValTok{-1}
\NormalTok{betaG <-}\StringTok{ }\FloatTok{0.3}
\NormalTok{betaE <-}\StringTok{ }\DecValTok{0}
\NormalTok{betaGE <-}\StringTok{ }\FloatTok{0.1}
\NormalTok{ylat <-}\StringTok{ }\NormalTok{beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{betaG}\OperatorTok{*}\NormalTok{G }\OperatorTok{+}\StringTok{ }\NormalTok{betaE}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\NormalTok{betaGE}\OperatorTok{*}\NormalTok{G}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}

\NormalTok{mod <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(ylat}\OperatorTok{~}\NormalTok{G}\OperatorTok{+}\NormalTok{E}\OperatorTok{+}\KeywordTok{I}\NormalTok{(G}\OperatorTok{*}\NormalTok{E), }\DataTypeTok{family =} \KeywordTok{gaussian}\NormalTok{(}\DataTypeTok{link =} \StringTok{"identity"}\NormalTok{))}


\CommentTok{#### Get the design matrix:}
\NormalTok{X <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,N),mod}\OperatorTok{$}\NormalTok{model[,}\OperatorTok{-}\DecValTok{1}\NormalTok{])}

\CommentTok{### Compute the weight matrix W:}
\NormalTok{beta <-}\StringTok{ }\KeywordTok{c}\NormalTok{(beta0,betaG,betaE,betaGE)}



\CommentTok{### The true information matrix}
\NormalTok{I <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(}\KeywordTok{t}\NormalTok{(X)) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(X)}



\CommentTok{#### Invert to get the true covariance matrix }
\NormalTok{V <-}\StringTok{ }\KeywordTok{solve}\NormalTok{(I)}


\CommentTok{### Compute the power function }

\CommentTok{### Assume d = beta0 - beta1, where beta0 = 0 is what we are testing as null:}
\NormalTok{delta <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{V[}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{])}\OperatorTok{*}\NormalTok{(}\DecValTok{0}\OperatorTok{-}\NormalTok{beta[}\DecValTok{4}\NormalTok{])}
\NormalTok{alpha <-}\StringTok{ }\FloatTok{0.05}
\NormalTok{Power <-}\StringTok{ }\DecValTok{1}\OperatorTok{-}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(delta }\OperatorTok{-}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(alpha}\OperatorTok{/}\DecValTok{2}\NormalTok{)) }\OperatorTok{+}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(delta }\OperatorTok{+}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(alpha}\OperatorTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{Power}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6030156
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#### Illustrate that this power is correct:}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{p1 <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{1000}\NormalTok{) \{}
\NormalTok{  ylat <-}\StringTok{ }\NormalTok{beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{betaG}\OperatorTok{*}\NormalTok{G }\OperatorTok{+}\StringTok{ }\NormalTok{betaE}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\NormalTok{betaGE}\OperatorTok{*}\NormalTok{G}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}
\NormalTok{  mod <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(ylat}\OperatorTok{~}\NormalTok{G}\OperatorTok{+}\NormalTok{E}\OperatorTok{+}\KeywordTok{I}\NormalTok{(G}\OperatorTok{*}\NormalTok{E), }\DataTypeTok{family =} \KeywordTok{gaussian}\NormalTok{(}\DataTypeTok{link =} \StringTok{"identity"}\NormalTok{))}
\NormalTok{  p1[i] <-}\StringTok{ }\KeywordTok{summary}\NormalTok{(mod)}\OperatorTok{$}\NormalTok{coefficient[}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{]}
\NormalTok{\}}
\NormalTok{emp_power <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(p1 }\OperatorTok{<=}\StringTok{ }\NormalTok{alpha)}
\NormalTok{emp_power}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.575
\end{verbatim}

We can see that both the theoretical power and empirical power are not
changed at all.

\hypertarget{assume-data-generated-from-probit-regression-model}{%
\subsection{Assume data generated from probit regression
model}\label{assume-data-generated-from-probit-regression-model}}

Here, we consider the binary trait generated from a probit regression
model:

First case, we consider the true \(\beta_{GE} = 0.1\) and true main
effect \(\beta_E=1\):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{N <-}\StringTok{ }\DecValTok{1000}
\NormalTok{G <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),}\DataTypeTok{size =}\NormalTok{ N, }\DataTypeTok{replace =}\NormalTok{ T, }\DataTypeTok{prob =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.16}\NormalTok{,}\FloatTok{0.48}\NormalTok{, }\FloatTok{0.36}\NormalTok{))}
\NormalTok{E <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}
\NormalTok{beta0 <-}\StringTok{ }\DecValTok{-1}
\NormalTok{betaG <-}\StringTok{ }\FloatTok{0.3}
\NormalTok{betaE <-}\StringTok{ }\DecValTok{1}
\NormalTok{betaGE <-}\StringTok{ }\FloatTok{0.1}
\NormalTok{ylat <-}\StringTok{ }\NormalTok{beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{betaG}\OperatorTok{*}\NormalTok{G }\OperatorTok{+}\StringTok{ }\NormalTok{betaE}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\NormalTok{betaGE}\OperatorTok{*}\NormalTok{G}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}
\NormalTok{y <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(ylat }\OperatorTok{>=}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{mod <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\NormalTok{G}\OperatorTok{+}\NormalTok{E}\OperatorTok{+}\KeywordTok{I}\NormalTok{(G}\OperatorTok{*}\NormalTok{E), }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"probit"}\NormalTok{))}


\CommentTok{#### Get the design matrix:}
\NormalTok{X <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,N),mod}\OperatorTok{$}\NormalTok{model[,}\OperatorTok{-}\DecValTok{1}\NormalTok{])}

\CommentTok{### Compute the weight matrix W:}
\NormalTok{beta <-}\StringTok{ }\KeywordTok{c}\NormalTok{(beta0,betaG,betaE,betaGE)}
\CommentTok{#beta <- as.numeric(mod$coefficients)}

\NormalTok{w <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N) \{}
\NormalTok{  si <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(X[i,]) }\OperatorTok{%*%}\StringTok{ }\NormalTok{beta)}
\NormalTok{  w[i] <-}\StringTok{ }\NormalTok{(}\KeywordTok{dnorm}\NormalTok{(si)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\NormalTok{(}\KeywordTok{pnorm}\NormalTok{(si)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pnorm}\NormalTok{(si)))}
\NormalTok{\}}

\CommentTok{### The true information matrix}
\NormalTok{I <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(}\KeywordTok{t}\NormalTok{(X)) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{diag}\NormalTok{(w,}\DataTypeTok{nrow =}\NormalTok{ N,}\DataTypeTok{ncol =}\NormalTok{ N) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(X)}



\CommentTok{#### Invert to get the true covariance matrix }
\NormalTok{V <-}\StringTok{ }\KeywordTok{solve}\NormalTok{(I)}



\CommentTok{### Compute the power function }

\CommentTok{### Assume d = beta0 - beta1, where beta0 = 0 is what we are testing as null:}
\NormalTok{delta <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{V[}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{])}\OperatorTok{*}\NormalTok{(}\DecValTok{0}\OperatorTok{-}\NormalTok{beta[}\DecValTok{4}\NormalTok{])}
\NormalTok{alpha <-}\StringTok{ }\FloatTok{0.05}
\NormalTok{Power <-}\StringTok{ }\DecValTok{1}\OperatorTok{-}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(delta }\OperatorTok{-}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(alpha}\OperatorTok{/}\DecValTok{2}\NormalTok{)) }\OperatorTok{+}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(delta }\OperatorTok{+}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(alpha}\OperatorTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{Power}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1723627
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#### Illustrate that this power is correct:}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{p1 <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{1000}\NormalTok{) \{}
\NormalTok{  ylat <-}\StringTok{ }\NormalTok{beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{betaG}\OperatorTok{*}\NormalTok{G }\OperatorTok{+}\StringTok{ }\NormalTok{betaE}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\NormalTok{betaGE}\OperatorTok{*}\NormalTok{G}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}
\NormalTok{  y <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(ylat }\OperatorTok{>=}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{  mod <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\NormalTok{G}\OperatorTok{+}\NormalTok{E}\OperatorTok{+}\KeywordTok{I}\NormalTok{(G}\OperatorTok{*}\NormalTok{E), }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"probit"}\NormalTok{))}
\NormalTok{  p1[i] <-}\StringTok{ }\KeywordTok{summary}\NormalTok{(mod)}\OperatorTok{$}\NormalTok{coefficient[}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{]}
\NormalTok{\}}
\NormalTok{emp_power <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(p1 }\OperatorTok{<=}\StringTok{ }\NormalTok{alpha)}
\NormalTok{emp_power}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.167
\end{verbatim}

Second case, we consider the true \(\beta_{GE} = 0.1\) fixed but change
the true main effect \(\beta_E\) from 1 to 0:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{N <-}\StringTok{ }\DecValTok{1000}
\NormalTok{G <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),}\DataTypeTok{size =}\NormalTok{ N, }\DataTypeTok{replace =}\NormalTok{ T, }\DataTypeTok{prob =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.16}\NormalTok{,}\FloatTok{0.48}\NormalTok{, }\FloatTok{0.36}\NormalTok{))}
\NormalTok{E <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}
\NormalTok{beta0 <-}\StringTok{ }\DecValTok{-1}
\NormalTok{betaG <-}\StringTok{ }\FloatTok{0.3}
\NormalTok{betaE <-}\StringTok{ }\DecValTok{0}
\NormalTok{betaGE <-}\StringTok{ }\FloatTok{0.1}
\NormalTok{ylat <-}\StringTok{ }\NormalTok{beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{betaG}\OperatorTok{*}\NormalTok{G }\OperatorTok{+}\StringTok{ }\NormalTok{betaE}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\NormalTok{betaGE}\OperatorTok{*}\NormalTok{G}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}
\NormalTok{y <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(ylat }\OperatorTok{>=}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{mod <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\NormalTok{G}\OperatorTok{+}\NormalTok{E}\OperatorTok{+}\KeywordTok{I}\NormalTok{(G}\OperatorTok{*}\NormalTok{E), }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"probit"}\NormalTok{))}


\CommentTok{#### Get the design matrix:}
\NormalTok{X <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,N),mod}\OperatorTok{$}\NormalTok{model[,}\OperatorTok{-}\DecValTok{1}\NormalTok{])}

\CommentTok{### Compute the weight matrix W:}
\NormalTok{beta <-}\StringTok{ }\KeywordTok{c}\NormalTok{(beta0,betaG,betaE,betaGE)}
\CommentTok{#beta <- as.numeric(mod$coefficients)}

\NormalTok{w <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N) \{}
\NormalTok{  si <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(X[i,]) }\OperatorTok{%*%}\StringTok{ }\NormalTok{beta)}
\NormalTok{  w[i] <-}\StringTok{ }\NormalTok{(}\KeywordTok{dnorm}\NormalTok{(si)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\NormalTok{(}\KeywordTok{pnorm}\NormalTok{(si)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pnorm}\NormalTok{(si)))}
\NormalTok{\}}

\CommentTok{### The true information matrix}
\NormalTok{I <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(}\KeywordTok{t}\NormalTok{(X)) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{diag}\NormalTok{(w,}\DataTypeTok{nrow =}\NormalTok{ N,}\DataTypeTok{ncol =}\NormalTok{ N) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(X)}



\CommentTok{#### Invert to get the true covariance matrix }
\NormalTok{V <-}\StringTok{ }\KeywordTok{solve}\NormalTok{(I)}



\CommentTok{### Compute the power function }

\CommentTok{### Assume d = beta0 - beta1, where beta0 = 0 is what we are testing as null:}
\NormalTok{delta <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{V[}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{])}\OperatorTok{*}\NormalTok{(}\DecValTok{0}\OperatorTok{-}\NormalTok{beta[}\DecValTok{4}\NormalTok{])}
\NormalTok{alpha <-}\StringTok{ }\FloatTok{0.05}
\NormalTok{Power <-}\StringTok{ }\DecValTok{1}\OperatorTok{-}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(delta }\OperatorTok{-}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(alpha}\OperatorTok{/}\DecValTok{2}\NormalTok{)) }\OperatorTok{+}\StringTok{ }\KeywordTok{pnorm}\NormalTok{(delta }\OperatorTok{+}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(alpha}\OperatorTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{Power}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3541068
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#### Illustrate that this power is correct:}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{p1 <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{1000}\NormalTok{) \{}
\NormalTok{  ylat <-}\StringTok{ }\NormalTok{beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{betaG}\OperatorTok{*}\NormalTok{G }\OperatorTok{+}\StringTok{ }\NormalTok{betaE}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\NormalTok{betaGE}\OperatorTok{*}\NormalTok{G}\OperatorTok{*}\NormalTok{E }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(N)}
\NormalTok{  y <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(ylat }\OperatorTok{>=}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{  mod <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\NormalTok{G}\OperatorTok{+}\NormalTok{E}\OperatorTok{+}\KeywordTok{I}\NormalTok{(G}\OperatorTok{*}\NormalTok{E), }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"probit"}\NormalTok{))}
\NormalTok{  p1[i] <-}\StringTok{ }\KeywordTok{summary}\NormalTok{(mod)}\OperatorTok{$}\NormalTok{coefficient[}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{]}
\NormalTok{\}}
\NormalTok{emp_power <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(p1 }\OperatorTok{<=}\StringTok{ }\NormalTok{alpha)}
\NormalTok{emp_power}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.35
\end{verbatim}

We can see that both the theoretical power and empirical power increased
greatly.

\end{document}
