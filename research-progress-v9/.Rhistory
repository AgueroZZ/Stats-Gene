### Generate the auxiliary variable:
Z <- rnorm(n = length(G_using[,1]), sd = 1)
### Generate the latent variable:
y_lat <- b0 + bG*G_using[,POS_using == POS_EFF] + bE*E + bZ*Z + bint*E*G_using[,POS_using == POS_EFF] + rnorm(n = length(G_using[,1]), sd = 0.5)
case_new <- ifelse(y_lat > 0, 1, 0)
### case_control ratio:
table(case_new)
#### Testing for interaction effect
### Assuming additive model: Testing for non-linearity
waldstats_P1 <- c()
p_vals_P1 <- c()
for (i in 1:ncol(G_using)) {
Gi <- G_using[,i]
if(length(unique(Gi)) != 3){
waldstats_P1[i] <- 0
p_vals_P1[i] <- -1
}
else{
modi <- glm(case_new ~ factor(Gi)*Z, family = binomial(link = "probit"))
if(any(is.na(modi$coefficients))){
waldstats_P1[i] <- 0
p_vals_P1[i] <- -1
}
else{
waldstats_P1[i] <- as.numeric(aod::wald.test(vcov(modi)[-c(1,4),-c(1,4)], b = modi$coefficients[-c(1,4)], H0 = matrix(0,nrow = 3,ncol = 1), L = matrix(c(2,-1,0,0,0,0,1,0,0,0,0,1),nrow = 3, byrow = T))$result$chi2[1])
p_vals_P1[i] <- as.numeric(aod::wald.test(vcov(modi)[-c(1,4),-c(1,4)], b = modi$coefficients[-c(1,4)], H0 = matrix(0,nrow = 3,ncol = 1), L = matrix(c(2,-1,0,0,0,0,1,0,0,0,0,1),nrow = 3, byrow = T))$result$chi2[3])
}
}
}
result_P_INT <- tibble(SNP = obj.bigSNP$map$marker.ID[Qualified_2], CHR = CHR_using, BP = POS_using , stats = waldstats_P1, P = p_vals_P1) %>% filter(P >= 0)
manhattan(result_P_INT, highlight = result_P_INT$SNP[which(POS_using %in% POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
qq(na.omit(result_P_INT)$P)
hist(result_P_INT$P, breaks = 30)
set.seed(123,sample.kind="Rounding")
### Sample three casual genes, corresponding to different MAF
freq_counts <- big_counts(G,ind.col = indx)
MAF <- snp_MAF(G,ind.col = indx)
Qualified <- freq_counts[3,] >= 30 & MAF>=0.05 & MAF<=0.1
POS_EFF1 <- sample(POS_using[Qualified], size = 1)
Qualified <- freq_counts[3,] >= 50 & MAF>=0.1 & MAF<=0.15
POS_EFF2 <- sample(POS_using[Qualified], size = 1)
Qualified <- freq_counts[3,] >= 80 & MAF>=0.15 & MAF<=0.2
POS_EFF3 <- sample(POS_using[Qualified], size = 1)
Qualified <- freq_counts[3,] >= 80 & MAF>=0.2 & MAF<=0.3
POS_EFF4 <- sample(POS_using[Qualified], size = 1)
Qualified <- freq_counts[3,] >= 100 & MAF>=0.3 & MAF<=0.4
POS_EFF5 <- sample(POS_using[Qualified], size = 1)
Qualified <- freq_counts[3,] >= 100 & MAF>=0.4
POS_EFF6 <- sample(POS_using[Qualified], size = 1)
### Computation:
### Compute power of each case:
suppressWarnings(power1 <- Compare_Aggreg_power_auxiliary(k = 200, G_using = G_using, POS_using = POS_using, effective_gene = POS_EFF1, sigma_eps = 0.5, sigmaE = 1))
power1 <- power1 <= 5 * (10 ^ -8)
power1 <- apply(power1, MARGIN = 2, FUN = mean)
suppressWarnings(power2 <- Compare_Aggreg_power_auxiliary(k = 200, G_using = G_using, POS_using = POS_using, effective_gene = POS_EFF2, sigma_eps = 0.5, sigmaE = 1))
Proposed_Aggreg <- function(k = 10, SNP_names, Gusing, POS_using, CHR_using, effective_gene, b0 = -1,bE = 0.1, bG = 0.6, bint1 = 0.3, sigmaE = 5,sigma_eps = 1){
result <- tibble()
cores= parallel::detectCores()
cl <- parallel::makeCluster(cores[1]-4) #not to overload your computer
doParallel::registerDoParallel(cl)
result <- foreach(i=1:k, .combine='rbind') %dopar% {
Do_once <- function(MySNP_names, G_using, MyPOS_using, MyCHR_using, Myeffective_gene, MybG = 0.3, Mybint1 = 0.6, MysigmaE = 5){
E <- rnorm(n = length(G_using[,1]), sd = sigmaE)
y_lat <- b0 + bE*E + bG*G_using[,POS_using == effective_gene] + bint1*E*G_using[,POS_using == effective_gene] + rnorm(n = length(G_using[,1]), sd = sigma_eps)
case_new <- ifelse(y_lat > 0, 1, 0)
waldstats_P1 <- c()
p_vals_P1 <- c()
for (i in 1:ncol(G_using)) {
Gi <- G_using[,i]
if(length(unique(Gi)) != 3){
waldstats_P1[i] <- 0
p_vals_P1[i] <- -1
}
else{
modi <- glm(case_new ~ factor(Gi), family = binomial(link = "probit"))
waldstats_P1[i] <- as.numeric(aod::wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[1])
p_vals_P1[i] <- as.numeric(aod::wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[3])
}
}
result_P_INT <- dplyr::tibble(SNP = SNP_names, CHR = CHR_using, BP = POS_using , stats = waldstats_P1, P = p_vals_P1)
}
Do_once(SNP_names, Gusing, POS_using, CHR_using, effective_gene, bG, bint1, sigmaE)
}
result
#stop cluster
parallel::stopCluster(cl)
result
}
### First randomly draw a position:
### Again, first take account of the linkage disequilibrium problem:
set.seed(12345,sample.kind="Rounding")
p <- 1
freq_counts <- big_counts(G)
MAF <- snp_MAF(G)
Qualified <- freq_counts[3,] >= 200 & MAF>=0.25
POS_EFF <- sample(POS[Qualified], size = 1)
indx <- which(CHR == CHR[which(POS == POS_EFF)])
G_using <- G[,indx]
CHR_using <- CHR[indx]
POS_using <- POS[indx]
### Let's repeat for 30 times
result <- Proposed_Aggreg(k = 10, SNP_names = obj.bigSNP$map$marker.ID[indx], Gusing = G_using, POS_using = POS_using, CHR_using = CHR_using, effective_gene = POS_EFF, bE = 0.3, bint = 0.8, bG = 0.8, sigmaE = 1, sigma_eps = 0.5) %>% filter(P >= 0)
manhattan(result, highlight = obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
qq(na.omit(result)$P)
hist(result$P, breaks = 30)
### Check for power:
classifications <- result %>% filter(BP == POS_EFF) %>% mutate(classified = ifelse(P <= (5 * (10 ^ -8)), 1, 0)) %>% select(classified) %>% pull()
sum(classifications)/length(classifications)
### Check for type I error rate:
error <- result %>% filter(BP != POS_EFF) %>% mutate(classified = ifelse(P <= (5 * (10 ^ -8)), 1, 0)) %>% select(classified) %>% pull()
sum(error)/length(error)
result
all(result$P >= 0)
manhattan(result, highlight = obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
qq(na.omit(result)$P)
hist(result$P, breaks = 30)
### Check for power:
classifications <- result %>% filter(BP == POS_EFF) %>% mutate(classified = ifelse(P <= (5 * (10 ^ -8)), 1, 0)) %>% select(classified) %>% pull()
sum(classifications)/length(classifications)
### Check for type I error rate:
error <- result %>% filter(BP != POS_EFF) %>% mutate(classified = ifelse(P <= (5 * (10 ^ -8)), 1, 0)) %>% select(classified) %>% pull()
sum(error)/length(error)
### Read in data:
path <- "D:/gwas-practice/indep_QC.bed"
tmpfile  <- tempfile()
snp_readBed(path, backingfile = tmpfile)
obj.bigSNP <- snp_attach(paste0(tmpfile , ".rds"))
G   <- obj.bigSNP$genotypes
CHR <- obj.bigSNP$map$chromosome
POS <- obj.bigSNP$map$physical.pos
# Check some counts for the 10 first SNPs
big_counts(G, ind.col = 1:10)
### Randomly generate case/control data under the null hypothesis
set.seed(12345,sample.kind="Rounding")
case <- rbinom(nrow(G),size = 1,prob = 0.3)
obj.bigSNP$fam$case <- case
### Testing for main effects using Logistic regression:
obj.gwas <- big_univLogReg(G, y01.train = case,
ncores = 6L, maxiter = 100)
### QQ plot, Manhattan plot and Genomic Control
snp_qq(gwas = obj.gwas)
snp_manhattan(gwas = obj.gwas, infos.chr = CHR, infos.pos = POS)
### Histogram of p-values:
p_vals <- 2*pnorm(-abs(obj.gwas$score))
hist(p_vals, breaks = 30)
load("D:/gwas-practice/additive_testing.Rdata")
## View of the result
head(result_P1)
## QQ plot of p-values
qq(na.omit(result_P1$P))
## Manhattan plot of p-values:
manhattan(na.omit(result_P1), suggestiveline = F,genomewideline = -log(0.05/nrow(G)))
## Histogram of p-values:
hist(result_P1$P, breaks = 30)
knitr::opts_chunk$set(echo = TRUE, dev = 'png', message = F, warning = F)
library(tidyverse)
library(lme4)
library(bigsnpr)
library(bigstatsr)
library(dplyr)
library(nlme)
library(aod)
library(qqman)
library(foreach)
library(doParallel)
### Read in data:
path <- "D:/gwas-practice/indep_QC.bed"
tmpfile  <- tempfile()
snp_readBed(path, backingfile = tmpfile)
obj.bigSNP <- snp_attach(paste0(tmpfile , ".rds"))
G   <- obj.bigSNP$genotypes
CHR <- obj.bigSNP$map$chromosome
POS <- obj.bigSNP$map$physical.pos
# Check some counts for the 10 first SNPs
big_counts(G, ind.col = 1:10)
### Randomly generate case/control data under the null hypothesis
set.seed(12345,sample.kind="Rounding")
case <- rbinom(nrow(G),size = 1,prob = 0.3)
obj.bigSNP$fam$case <- case
### Testing for main effects using Logistic regression:
obj.gwas <- big_univLogReg(G, y01.train = case,
ncores = 6L, maxiter = 100)
### QQ plot, Manhattan plot and Genomic Control
snp_qq(gwas = obj.gwas)
snp_manhattan(gwas = obj.gwas, infos.chr = CHR, infos.pos = POS)
### Histogram of p-values:
p_vals <- 2*pnorm(-abs(obj.gwas$score))
hist(p_vals, breaks = 30)
load("D:/gwas-practice/additive_testing.Rdata")
## View of the result
head(result_P1)
## QQ plot of p-values
qq(na.omit(result_P1$P))
## Manhattan plot of p-values:
manhattan(na.omit(result_P1), suggestiveline = F,genomewideline = -log(0.05/nrow(G)))
## Histogram of p-values:
hist(result_P1$P, breaks = 30)
############### Power of the proposed method for interaction: With one casual genes
### Again, first take account of the linkage disequilibrium problem:
set.seed(123,sample.kind="Rounding")
indx <- 1:ncol(G)
G_using <- G[,indx]
CHR_using <- CHR[indx]
POS_using <- POS[indx]
### Randomly sample 1 genes:
p <- 1
### Need to make sure that all genotypes have enough frequencies in the selected genes:
freq_counts <- big_counts(G,ind.col = indx)
MAF <- snp_MAF(G,ind.col = indx)
Qualified <- freq_counts[3,] >= 200 & MAF>=0.3
POS_EFF <- sample(POS_using[Qualified], size = 1)
### Randomly sample 1/2 genes with strong effects and 1/2 genes with weak effects
b0 <- -1
bG <- 0.8
bint <- 0.8
bE <- 0.3
### Generate the underlying environment variable:
E <- rnorm(n = length(G_using[,1]), sd = 1)
### Generate the latent variable:
y_lat <- b0 + bG*G_using[,POS_using == POS_EFF] + bE*E + bint*E*G_using[,POS_using == POS_EFF] + rnorm(n = length(G_using[,1]), sd = 0.5)
case_new <- ifelse(y_lat > 0, 1, 0)
### case_control ratio:
table(case_new)
#### Testing for interaction effect
### Assuming additive model: Testing for non-linearity
waldstats_P1 <- c()
p_vals_P1 <- c()
for (i in 1:ncol(G_using)) {
Gi <- G_using[,i]
if(length(unique(Gi)) != 3){
waldstats_P1[i] <- 0
p_vals_P1[i] <- -1
}
else{
modi <- glm(case_new ~ factor(Gi), family = binomial(link = "probit"))
waldstats_P1[i] <- as.numeric(wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[1])
p_vals_P1[i] <- as.numeric(wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[3])
}
}
result_P_INT <- tibble(SNP = obj.bigSNP$map$marker.ID[indx], CHR = CHR_using, BP = POS_using , stats = waldstats_P1, P = p_vals_P1) %>% filter(P >= 0)
### diagnostic plots:
manhattan(result_P_INT, highlight = result_P_INT$SNP[which(POS_using %in% POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
qq(na.omit(result_P_INT)$P)
hist(result_P_INT$P, breaks = 30)
result_P_INT[result_P_INT$BP %in% POS_EFF, ]
Proposed_Aggreg <- function(k = 10, SNP_names, Gusing, POS_using, CHR_using, effective_gene, b0 = -1,bE = 0.1, bG = 0.6, bint1 = 0.3, sigmaE = 5,sigma_eps = 1){
result <- tibble()
cores= parallel::detectCores()
cl <- parallel::makeCluster(cores[1]-4) #not to overload your computer
doParallel::registerDoParallel(cl)
result <- foreach(i=1:k, .combine='rbind') %dopar% {
Do_once <- function(MySNP_names, G_using, MyPOS_using, MyCHR_using, Myeffective_gene, MybG = 0.3, Mybint1 = 0.6, MysigmaE = 5){
E <- rnorm(n = length(G_using[,1]), sd = sigmaE)
y_lat <- b0 + bE*E + bG*G_using[,POS_using == effective_gene] + bint1*E*G_using[,POS_using == effective_gene] + rnorm(n = length(G_using[,1]), sd = sigma_eps)
case_new <- ifelse(y_lat > 0, 1, 0)
waldstats_P1 <- c()
p_vals_P1 <- c()
for (i in 1:ncol(G_using)) {
Gi <- G_using[,i]
if(length(unique(Gi)) != 3){
waldstats_P1[i] <- 0
p_vals_P1[i] <- -1
}
else{
modi <- glm(case_new ~ factor(Gi), family = binomial(link = "probit"))
waldstats_P1[i] <- as.numeric(aod::wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[1])
p_vals_P1[i] <- as.numeric(aod::wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[3])
}
}
result_P_INT <- dplyr::tibble(SNP = SNP_names, CHR = CHR_using, BP = POS_using , stats = waldstats_P1, P = p_vals_P1)
}
Do_once(SNP_names, Gusing, POS_using, CHR_using, effective_gene, bG, bint1, sigmaE)
}
result
#stop cluster
parallel::stopCluster(cl)
result
}
knitr::opts_chunk$set(echo = TRUE, dev = 'png', message = F, warning = F)
library(tidyverse)
library(lme4)
library(bigsnpr)
library(bigstatsr)
library(dplyr)
library(nlme)
library(aod)
library(qqman)
library(foreach)
library(doParallel)
### Read in data:
path <- "D:/gwas-practice/indep_QC.bed"
tmpfile  <- tempfile()
snp_readBed(path, backingfile = tmpfile)
obj.bigSNP <- snp_attach(paste0(tmpfile , ".rds"))
G   <- obj.bigSNP$genotypes
CHR <- obj.bigSNP$map$chromosome
POS <- obj.bigSNP$map$physical.pos
# Check some counts for the 10 first SNPs
big_counts(G, ind.col = 1:10)
### Randomly generate case/control data under the null hypothesis
set.seed(12345,sample.kind="Rounding")
case <- rbinom(nrow(G),size = 1,prob = 0.3)
obj.bigSNP$fam$case <- case
### Testing for main effects using Logistic regression:
obj.gwas <- big_univLogReg(G, y01.train = case,
ncores = 6L, maxiter = 100)
### QQ plot, Manhattan plot and Genomic Control
snp_qq(gwas = obj.gwas)
snp_manhattan(gwas = obj.gwas, infos.chr = CHR, infos.pos = POS)
### Histogram of p-values:
p_vals <- 2*pnorm(-abs(obj.gwas$score))
hist(p_vals, breaks = 30)
load("D:/gwas-practice/additive_testing.Rdata")
## View of the result
head(result_P1)
## QQ plot of p-values
qq(na.omit(result_P1$P))
## Manhattan plot of p-values:
manhattan(na.omit(result_P1), suggestiveline = F,genomewideline = -log(0.05/nrow(G)))
## Histogram of p-values:
hist(result_P1$P, breaks = 30)
############### Power of the proposed method for interaction: With one casual genes
### Again, first take account of the linkage disequilibrium problem:
set.seed(123,sample.kind="Rounding")
indx <- 1:ncol(G)
G_using <- G[,indx]
CHR_using <- CHR[indx]
POS_using <- POS[indx]
### Randomly sample 1 genes:
p <- 1
### Need to make sure that all genotypes have enough frequencies in the selected genes:
freq_counts <- big_counts(G,ind.col = indx)
MAF <- snp_MAF(G,ind.col = indx)
Qualified <- freq_counts[3,] >= 200 & MAF>=0.3
POS_EFF <- sample(POS_using[Qualified], size = 1)
### Randomly sample 1/2 genes with strong effects and 1/2 genes with weak effects
b0 <- -1
bG <- 0.8
bint <- 0.8
bE <- 0.3
### Generate the underlying environment variable:
E <- rnorm(n = length(G_using[,1]), sd = 1)
### Generate the latent variable:
y_lat <- b0 + bG*G_using[,POS_using == POS_EFF] + bE*E + bint*E*G_using[,POS_using == POS_EFF] + rnorm(n = length(G_using[,1]), sd = 0.5)
case_new <- ifelse(y_lat > 0, 1, 0)
### case_control ratio:
table(case_new)
#### Testing for interaction effect
### Assuming additive model: Testing for non-linearity
waldstats_P1 <- c()
p_vals_P1 <- c()
for (i in 1:ncol(G_using)) {
Gi <- G_using[,i]
if(length(unique(Gi)) != 3){
waldstats_P1[i] <- 0
p_vals_P1[i] <- -1
}
else{
modi <- glm(case_new ~ factor(Gi), family = binomial(link = "probit"))
waldstats_P1[i] <- as.numeric(wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[1])
p_vals_P1[i] <- as.numeric(wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[3])
}
}
result_P_INT <- tibble(SNP = obj.bigSNP$map$marker.ID[indx], CHR = CHR_using, BP = POS_using , stats = waldstats_P1, P = p_vals_P1) %>% filter(P >= 0)
### diagnostic plots:
manhattan(result_P_INT, highlight = result_P_INT$SNP[which(POS_using %in% POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
qq(na.omit(result_P_INT)$P)
hist(result_P_INT$P, breaks = 30)
result_P_INT[result_P_INT$BP %in% POS_EFF, ]
Proposed_Aggreg <- function(k = 10, SNP_names, Gusing, POS_using, CHR_using, effective_gene, b0 = -1,bE = 0.1, bG = 0.6, bint1 = 0.3, sigmaE = 5,sigma_eps = 1){
result <- tibble()
cores= parallel::detectCores()
cl <- parallel::makeCluster(cores[1]-4) #not to overload your computer
doParallel::registerDoParallel(cl)
result <- foreach(i=1:k, .combine='rbind') %dopar% {
Do_once <- function(MySNP_names, G_using, MyPOS_using, MyCHR_using, Myeffective_gene, MybG = 0.3, Mybint1 = 0.6, MysigmaE = 5){
E <- rnorm(n = length(G_using[,1]), sd = sigmaE)
y_lat <- b0 + bE*E + bG*G_using[,POS_using == effective_gene] + bint1*E*G_using[,POS_using == effective_gene] + rnorm(n = length(G_using[,1]), sd = sigma_eps)
case_new <- ifelse(y_lat > 0, 1, 0)
waldstats_P1 <- c()
p_vals_P1 <- c()
for (i in 1:ncol(G_using)) {
Gi <- G_using[,i]
if(length(unique(Gi)) != 3){
waldstats_P1[i] <- 0
p_vals_P1[i] <- -1
}
else{
modi <- glm(case_new ~ factor(Gi), family = binomial(link = "probit"))
waldstats_P1[i] <- as.numeric(aod::wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[1])
p_vals_P1[i] <- as.numeric(aod::wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[3])
}
}
result_P_INT <- dplyr::tibble(SNP = SNP_names, CHR = CHR_using, BP = POS_using , stats = waldstats_P1, P = p_vals_P1)
}
Do_once(SNP_names, Gusing, POS_using, CHR_using, effective_gene, bG, bint1, sigmaE)
}
result
#stop cluster
parallel::stopCluster(cl)
result
}
Proposed_Aggreg <- function(k = 10, SNP_names, Gusing, POS_using, CHR_using, effective_gene, b0 = -1,bE = 0.1, bG = 0.6, bint1 = 0.3, sigmaE = 5,sigma_eps = 1){
result <- tibble()
cores= parallel::detectCores()
cl <- parallel::makeCluster(cores[1]-4) #not to overload your computer
doParallel::registerDoParallel(cl)
result <- foreach(i=1:k, .combine='rbind') %dopar% {
Do_once <- function(MySNP_names, G_using, MyPOS_using, MyCHR_using, Myeffective_gene, MybG = 0.3, Mybint1 = 0.6, MysigmaE = 5){
E <- rnorm(n = length(G_using[,1]), sd = sigmaE)
y_lat <- b0 + bE*E + bG*G_using[,POS_using == effective_gene] + bint1*E*G_using[,POS_using == effective_gene] + rnorm(n = length(G_using[,1]), sd = sigma_eps)
case_new <- ifelse(y_lat > 0, 1, 0)
waldstats_P1 <- c()
p_vals_P1 <- c()
for (i in 1:ncol(G_using)) {
Gi <- G_using[,i]
if(length(unique(Gi)) != 3){
waldstats_P1[i] <- 0
p_vals_P1[i] <- -1
}
else{
modi <- glm(case_new ~ factor(Gi), family = binomial(link = "probit"))
waldstats_P1[i] <- as.numeric(aod::wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[1])
p_vals_P1[i] <- as.numeric(aod::wald.test(vcov(modi)[-1,-1], b = modi$coefficients[-1], H0 = matrix(0,nrow = 1,ncol = 1), L = matrix(c(2,-1),nrow = 1))$result$chi2[3])
}
}
result_P_INT <- dplyr::tibble(SNP = SNP_names, CHR = CHR_using, BP = POS_using , stats = waldstats_P1, P = p_vals_P1)
}
Do_once(SNP_names, Gusing, POS_using, CHR_using, effective_gene, bG, bint1, sigmaE)
}
result
#stop cluster
parallel::stopCluster(cl)
result
}
### First randomly draw a position:
### Again, first take account of the linkage disequilibrium problem:
set.seed(12345,sample.kind="Rounding")
p <- 1
freq_counts <- big_counts(G)
MAF <- snp_MAF(G)
Qualified <- freq_counts[3,] >= 200 & MAF>=0.25
POS_EFF <- sample(POS[Qualified], size = 1)
indx <- which(CHR == CHR[which(POS == POS_EFF)])
G_using <- G[,indx]
CHR_using <- CHR[indx]
POS_using <- POS[indx]
### Let's repeat for 30 times
result <- Proposed_Aggreg(k = 10, SNP_names = obj.bigSNP$map$marker.ID[indx], Gusing = G_using, POS_using = POS_using, CHR_using = CHR_using, effective_gene = POS_EFF, bE = 0.3, bint = 0.8, bG = 0.8, sigmaE = 1, sigma_eps = 0.5)
result <- result %>% filter(P >= 0)
manhattan(result, highlight = obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
manhattan(result, highlight = obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
result
obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)]
manhattan(result,  suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
result
?manhattan
hist(result$P)
summary(result$P)
?manhattan
result
manhattan(result, highlight = result_P_INT$SNP[which(POS_using %in% POS_EFF)], suggestiveline = FALSE)
manhattan(result, highlight = result_P_INT$SNP[which(POS_using %in% POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
manhattan(result, highlight = result_P_INT$SNP[which(POS_using %in% POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8))) + ylim(c(0,1))
?
ylim
manhattan(result, highlight = result_P_INT$SNP[which(POS_using %in% POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8))) + ylim(0,1)
qq(na.omit(result)$P)
hist(result$P, breaks = 30)
result
manhattan(result, highlight = result_P_INT$SNP[which(POS_using %in% POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
manhattan(result, highlight = result_P_INT$SNP[which(POS_using %in% POS_EFF)], suggestiveline = FALSE, genomewideline = F)
manhattan(result, highlight = result$SNP[which(POS_using %in% POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
result_P_INT
is.na(RESULT)
is.na(result)
any(is.na(result))
classifications <- result %>% filter(BP == POS_EFF) %>% mutate(classified = ifelse(P <= (5 * (10 ^ -8)), 1, 0)) %>% select(classified) %>% pull()
classifications
sum(classifications)/length(classifications)
result_P_INT$SNP[which(POS_using %in% POS_EFF)]
result$SNP[which(POS_using %in% POS_EFF)]
manhattan(result, highlight = obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
result
?manhattan
result[1:10,] %>% manhattan()
result[1:100,] %>% manhattan()
result[1:1000,] %>% manhattan()
result[1:10000,] %>% manhattan()
result[1:100000,] %>% manhattan()
result[1:200000,] %>% manhattan()
result[1:110000,] %>% manhattan()
result[1:100000,] %>% manhattan()
result[1:100005,] %>% manhattan()
nrow(result)
result[1:106810,] %>% manhattan()
result[1:106809,] %>% manhattan()
result[1:106000,] %>% manhattan()
tail(result)
result$P == 0
any(result$P == 0)
which(result$P == 0)
.Machine
sum(result$P == 0)
result <- result %>% filter(P > 0)
manhattan(result, highlight = obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
qq(na.omit(result)$P)
hist(result$P, breaks = 30)
manhattan(result, highlight = obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
manhattan(result[100005:nrow(result),], highlight = obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
manhattan(result[100000:nrow(result),], highlight = obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
manhattan(result[80000:nrow(result),], highlight = obj.bigSNP$map$marker.ID[indx][which(POS_using == POS_EFF)], suggestiveline = FALSE, genomewideline = -log10(5 * (10 ^ -8)))
