---
title: "Progress report: Detecting interaction with unknown environmental covariate"
author: "Ziang Zhang"
date: "15/10/2020"
output: 
  pdf_document:
    keep_tex: true
    number_sections: true
    fig_caption: yes

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lme4)
library(bigsnpr)
library(bigstatsr)
library(dplyr)
library(nlme)
library(aod)
library(qqman)
```

# The Underlying Model:


For binary response variable, it is often assumed that the response variable $y_i$ conditioning on the regressors $G_i,Z_i$ come from a latent model such that:
\begin{equation}\label{eqn:latentformulation}
\begin{aligned}
Y_i^* &= \beta_0 + \beta_G G_i + \beta_Z Z_i + \epsilon_i \\
Y_i &= I\{Y_i^*>0\} \\
\end{aligned}
\end{equation}

The unobserved latent variable $Y_i^*$ determines whether the observed response variable $Y_i$ is 0 or 1. The error term $\epsilon_i$ in $Y_i^*$ needs to have a completely known distribution, which can be $\text{N}(0,1)$ for the model of $Y|G,Z$ to become a probit model, or a logistic distribution with mean 0 and variance 3.28 for the model to become a logistic regression model. 

Here the regressor $G_i$ represents the allele of interest, and the regressor $Z_i$ is any regressor that can be non-genetic. For now on, we will assume the model is probit for simplicity, unless otherwise indicated.


Similarly, we can have a Genotypic Model defined as:  
\begin{equation}\label{eqn:latentformulationGeno}
\begin{aligned}
Y_i^* &= \beta_0 + \beta_{G1} I(G_i = 1) + \beta_{G2} I(G_i = 2) + \beta_Z Z_i + \epsilon_i \\
Y_i &= I\{Y_i^*>0\} \\
\end{aligned}
\end{equation}

The Genotypic Model has higher degree of freedom than the additive model due to the extra regression parameter.



## When the true model does contain gene-environment interaction

Assume for simplicity that $E_i$ the environmental variable has a normal distribution with mean $\mu_E$ and variance $\sigma_E^2$, and suppose that the true underlying model is:
\begin{equation}\label{eqn:probitModelWithInteraction}
\begin{aligned}
Y_i^* &= \beta_0 + \beta_G G_i + \beta_Z Z_i + \beta_E E_i + \beta_{G\times E} G_i \times E_i + \epsilon_i \\
Y_i &= I\{Y_i^*>0\} \\
\epsilon_i &\sim \text{N}(0,1)
\end{aligned}
\end{equation}

Furthermore, we can compute that:
\begin{equation}\label{eqn:probitModelWithInteraction_MeanVar}
\begin{aligned}
\text{E}(Y_i^*|G_i,Z_i) &= \beta_0 + \beta_E \mu_E + (\beta_G + \beta_{G\times E} \mu_E)G_i + \beta_Z Z_i \\
\text{Var}(Y_i^*|G_i,Z_i) &= (\beta_{G\times E} G_i)^2 \sigma_E^2 + \beta_E^2 \sigma_E^2 + 1 \\
Y_i^*|G_i, Z_i &\sim \text{N}\bigg(\beta_0 + \beta_E \mu_E + (\beta_G + \beta_{G\times E} \mu_E)G_i + \beta_Z Z_i, (\beta_{G\times E} G_i)^2 \sigma_E^2 + \beta_E^2 \sigma_E^2 + 1 \bigg)
\end{aligned}
\end{equation}

That implies that the probability we get a case for different levels of $G_i$ and $Z_i$ will be:
\begin{equation}\label{eqn:probitModelWithInteraction_Prob} 
\begin{aligned} 
\text{P}(Y = 1 | G_i, Z_i) &= \text{P}(Y^* > 0| G_i, Z_i) \\ 
                           &= \text{P}(\frac{Y^*  - \text{E}(Y^* |G_i,Z_i)}{\sqrt{\text{Var}(Y^* |G_i,Z_i)}} > \frac{-\text{E}(Y^* |G_i,Z_i)}{\sqrt{\text{Var}(Y^* |G_i,Z_i)}}) \\
                           &= \Phi \bigg( \frac{\text{E}(Y^* |G_i,Z_i)}{\sqrt{\text{Var}(Y^* |G_i,Z_i)}} \bigg)
\end{aligned}
\end{equation}


Therefore, applying the inverse CDF on both sides, we get $$\Phi^{-1} \bigg(\text{P}(Y = 1 | G, Z) \bigg) = \frac{\beta_0+\beta_E \mu_E+(\beta_G + \beta_{G\times E} \mu_E)G_i + \beta_Z Z}{\sqrt{(\beta_{G\times E}^2 G_i^2 \sigma_E^2 + \beta_E^2 \sigma_E^2 + 1)}} $$ 

This is only a linear function of $G_i$ when the interaction parameter $\beta_{G\times E} = 0$, and the slope of Z is constant across different genes only when $\beta_{G\times E}$ is zero.

\begin{enumerate}
\item If the true underlying model also contains another regressor $W$ but $W$ is uncorrelated with $G$ for example. Then even though ignoring that regressor breaks the structural assumption of probit model, so that the fitted model without $W$ is no longer a probit model (since now $\epsilon$ does not follow standard normal), but $\Phi^{-1}(\text{P}(Y_i = 1|G_i,Z_i))$ will still be a linear function of $G_i$. So detecting based on the linearity of $\Phi^{-1}\text{P}$ will not be affected by omitted exogenous regressors.
\item Since $P(Y_i = 1|G_i,Z_i)$ is actually unknown in practice, we can estimate it using the sample proportion $\hat{P}(Y = 1|G = g,Z = z) = \frac{\sum_{i=1}^{n} \text{I}\{y_i =1,G_{i} = g, Z_{i} = z\}}{\sum_{i=1}^{n}  \text{I}\{G_{i} = g, Z_{i} = z\}}$. We shouldn't use the fitted model to estimate them since our fitted model may be wrong.
\item The reason we used probit model instead of logistic model here is that assuming $E$ follows normal distribution, $Y^*|G,Z$ will still be normal if we omit the interaction term, since linear combination of normal is normal. But assuming $E$ follows logistic distribution does not imply that $Y^*|G,Z$ will be logistically distributed as logistic distribution is not closed under linear combination. However, logistic regression model for $Y|G,Z$ implies that $Y^*|G,Z$ must follow logistic distribution. In other words, probit regression model with omitted covariate will still be a probit regression model, just with different regression parameters. Based on the literature, it seems like probit model and logistic model have really closed results in real applications.
\end{enumerate}




If the model is Genotypic instead:
\begin{equation}\label{eqn:genointer}
\begin{aligned}
Y_i^* &= \beta_0 + \beta_{G1} I(G_i = 1) + \beta_{G2} I(G_i = 2) + \beta_Z Z_i + \beta_E E_i + \beta_{G1E} I(G_i = 1) \times E_i + \beta_{G2E} I(G_i = 2) \times E_i  + \epsilon_i \\
\end{aligned}
\end{equation}

then we can derive the following:
$$\Phi^{-1} \bigg(\text{P}(Y = 1 | G, Z) \bigg) = \frac{\beta_0+\beta_E \mu_E+(\beta_{G1} + \beta_{G1E} \mu_E)I(G = 1)+(\beta_{G2} + \beta_{G2E} \mu_E)I(G = 2) + \beta_Z Z}{\sqrt{(\beta_{G1E}^2 I(G = 1) \sigma_E^2 +\beta_{G2E}^2 I(G = 2) \sigma_E^2 + \beta_E^2 \sigma_E^2 + 1)}} $$
In this case, the model will still be linear in $I(G = 1), I(G = 2)$ because of the extra parameter, just with different regression parameters. But the slope of Z will continue to differ between different Genetic types unless the there are no interaction effects $\beta_{G1E}$ and $\beta_{G2E}$.



\clearpage


# Method for Additive Model:

In this section, I will present two methods for the detection of interaction effect when the true model is additive.

## Testing of Linearity:
Recall that when the model is additive, then: $$\Phi^{-1} \bigg(\text{P}(Y = 1 | G, Z) \bigg) = \frac{\beta_0+\beta_E \mu_E+(\beta_G + \beta_{G\times E} \mu_E)G + \beta_Z Z}{\sqrt{(\beta_{G\times E}^2 G^2 \sigma_E^2 + \beta_E^2 \sigma_E^2 + 1)}}$$ 


This method relies on the checking of linearity of $\Phi^{-1}(P)$, so the test statistics will also be focusing on the detection of linearity. Note that the above 1 degree of freedom regression model, although it is not linear in $G$, it can be rewritten as a valid 2 degree of freedom genotypic model that is linear in $I(G=1), I(G=2)$:

\begin{equation}
\begin{aligned}
\Phi^{-1} \bigg(\text{P}(Y = 1 | G, Z) \bigg) &= \frac{\beta_0+\beta_E \mu_E+(\beta_G + \beta_{G\times E} \mu_E)G + \beta_Z Z}{\sqrt{(\beta_{G\times E}^2 G^2 \sigma_E^2 + \beta_E^2 \sigma_E^2 + 1)}} \\
                                              &= \gamma_0 + \gamma_1 I(G = 1) + \gamma_2 I(G=2) + \gamma_{Z1G} I(G=1) * Z + \gamma_{Z2G} I(G=2) * Z + \gamma_Z Z 
\end{aligned}
\end{equation}

Here, we can compute that:
\begin{equation}
\begin{aligned}
& \gamma_0 = \frac{\beta_0 + \beta_E \mu_E}{\sqrt{\beta_E^2 \sigma_E^2 + 1}} \\
& \gamma_1 = \frac{\beta_0 + \beta_E \mu_E + \beta_G + \beta_{G\times E} \mu_E}{\sqrt{\beta_{G\times E}^2 \sigma_E^2 + \beta_E^2 \sigma_E^2 + 1}} - \gamma_0 \\
& \gamma_2 = \frac{\beta_0 + \beta_E \mu_E + 2(\beta_G + \beta_{G\times E} \mu_E)}{\sqrt{4\beta_{G\times E}^2 \sigma_E^2 + \beta_E^2 \sigma_E^2 + 1}} - \gamma_0
\end{aligned}
\end{equation}

Therefore, we can conclude that if $\beta_{G\times E} = 0$, then $\beta_G =\gamma_1 = 2\gamma_2$ must hold. If we further have the information on the covariate $Z$, then we can increase the power of our detection by also testing on $\gamma_{Z1G} = \gamma_{Z2G} =0$ (equal slopes of Z across genotypes).


### Wald Test Statistics:

To test the null hypothesis of $\beta_{G\times E} = 0$, we can use the following steps:

\textbf{1. Rewrite the additive regression model:}
We first rewrite the additive regression model as a genotypic model, i.e: $$\Phi^{-1} \bigg(\text{P}(Y = 1 | G, Z) \bigg) = \gamma_0 + \gamma_1 I(G = 1) + \gamma_2 I(G=2) + \gamma_{Z1G} I(G=1) * Z + \gamma_{Z2G} I(G=2) * Z + \gamma_Z Z$$

Now, the regression parameters in this model may not carry very meaningful interpretations due to the potential presence of $\beta_{G\times E}$. However, we can use them to detect the presence of missing interaction effect by either testing $H_0: \gamma_1 = \gamma_2$ or $H_0: \gamma_1 = \gamma_2, \ \gamma_{Z1G}=\gamma_{Z2G} =0$, depending on whether the information of $Z$ is available, and whether $Z$ is ordinal.

\textbf{2. Wald Test on linearity:}
To test $H_0: \gamma_1 = \gamma_2$ or $H_0: \gamma_1 = \gamma_2, \ \gamma_{Z1G}=\gamma_{Z2G} =0$, we can simply do a Wald test on the genotypic working model that we considered above. It turns out that this Wald test statistic $T$ can also be equivalently derived through an application of Delta method on sample proportion, or as a two-stage linear regression. 

If we have information about the covariate $Z$ in the regression model, and $Z$ is an ordinal variable with additive effect, then the power of our test will be augmented if we test $H_0: \gamma_1 = \gamma_2, \ \gamma_{Z1G}=\gamma_{Z2G} =0$ in our Wald test. We can also only test $H_0: \gamma_{Z1G}=\gamma_{Z2G} =0$, this makes our test robust to the case that G's effect is actually non-additive. However, we then need to be more careful to make sure that $Z$ indeed has no interaction with G or E in the \textbf{true} model. 











# Method for Genotypic Model:


## Auxiliary variable method:

Recall for a Genotypic Model with interaction like below: 
\begin{equation}\label{eqn:genointer}
\begin{aligned}
Y_i^* &= \beta_0 + \beta_{G1} I(G_i = 1) + \beta_{G2} I(G_i = 2) + \beta_Z Z_i + \beta_E E_i + \beta_{G1E} I(G_i = 1) \times E_i + \beta_{G2E} I(G_i = 2) \times E_i  + \epsilon_i \\
\end{aligned}
\end{equation}


We can derive that:
\begin{equation}\label{eqn:RStest}
\begin{aligned}
\Phi^{-1} \bigg(\text{P}(Y = 1 | G, Z) \bigg) &= \frac{\beta_0+\beta_E \mu_E+(\beta_{G1} + \beta_{G1E} \mu_E)I(G = 1)+(\beta_{G2} + \beta_{G2E} \mu_E)I(G = 2) + \beta_Z Z}{\sqrt{(\beta_{G1E}^2 I(G = 1) \sigma_E^2 +\beta_{G2E}^2 I(G = 2) \sigma_E^2 + \beta_E^2 \sigma_E^2 + 1)}} \\
&= \gamma_0 + \gamma_1 I(G = 1) + \gamma_2 I(G = 2) + \gamma_Z Z + \gamma_{Z1G} I(G = 1) \times Z + \gamma_{Z2G} I(G = 2) \times Z
\end{aligned}
\end{equation}

where the new parameters $\gamma_{Z1G}$ and $\gamma_{Z2G}$ will be defined as:
$$\gamma_{Z1G} = \frac{\beta_Z}{\sqrt{\beta_E^2\sigma_E^2+\beta_{G1E}^2\sigma_E^2 +1}}-\frac{\beta_Z}{\sqrt{\beta_E^2\sigma_E^2 +1}} $$
and:
$$\gamma_{Z2G} = \frac{\beta_Z}{\sqrt{\beta_E^2\sigma_E^2+\beta_{G2E}^2\sigma_E^2 +1}}-\frac{\beta_Z}{\sqrt{\beta_E^2\sigma_E^2 +1}} $$


In other words, a Genotypic Model with an missing interaction can still be written as a linear function of these two indicator functions of G because of the extra regression parameter. However, ignoring this environment to gene interaction will create an artificial interaction between gene and the covariate Z. Since the interaction effects are zero if and only if the covariate Z has constant slopes across different genotypes, we can test the environmental interaction by testing the null hypothesis $H_0: \gamma_{Z1G} = \gamma_{Z2G} = 0$, using either wald test, likelihood ratio test or score test.

The key in this method is to test the equal slopes of the auxiliary variable $Z$. In order for this method to work, we need the following assumption:

\begin{enumerate}
\item The auxiliary variable $Z_i$ is assumed to have no interaction effect with G in the model conditional on G, Z and E.
\item The auxiliary variable $Z_i$ is also assumed to have no interaction effect with E in the model conditional on G, Z and E.
\end{enumerate}


\textbf{Main concern about genotypic model:} When we use the above method to test for the presence of GE interaction in a genotypic model, the power of our test is highly dependent on the true values for $\beta_Z$ and $\beta_{G\times E}$. Since $\gamma_{Z1G}$ and $\gamma_{Z2G}$ will eventually converge to $0$ as $\beta_Z$ gets closer to $0$, or as $\beta_{G\times E}$ gets closer to $0$. In other words, our method has very low power when: $$\frac{\beta_Z}{\sqrt{\beta_E^2\sigma_E^2+\beta_{G1E}^2\sigma_E^2 +1}} \approx \frac{\beta_Z}{\sqrt{\beta_E^2\sigma_E^2+\beta_{G2E}^2\sigma_E^2 +1}} \approx \frac{\beta_Z}{\sqrt{\beta_E^2\sigma_E^2+1}}$$










# GWAS Implementation on the 1000 Genome Project Data:

\textbf{Classical Testing for Main effect}


In this section, we will conduct a GWAS on the 1kGP dataset. The cleaned set of data has 1736 independent individuals and around 2 millions SNPs. However, since our analysis will be more sensitive to the low genotypic frequency of each gene, we will further have some additional quality control to make sure the genotypic frequency is high enough for each category. We further filtered SNPs in this dataset with threshold on MAF being $0.15$, and keep only the SNPs on autosomes. After this additional QC procedure, there are 1749 individuals with 150652 SNPs in our dataset. 

```{r}
### Read in data:
path <- "D:/gwas-practice/indep_QC.bed"
tmpfile  <- tempfile()
snp_readBed(path, backingfile = tmpfile)
obj.bigSNP <- snp_attach(paste0(tmpfile , ".rds"))

G   <- obj.bigSNP$genotypes
CHR <- obj.bigSNP$map$chromosome
POS <- obj.bigSNP$map$physical.pos

# Check some counts for the 10 first SNPs
big_counts(G, ind.col = 1:10)
```
We randomly assigned an individual to case or control, and assume the disease prevalence is 0.3. Firstly, we conduct the classical logistic regression to test the main effects. Because of the random assignment, the p-values should have similar behavior as $\text{Unif}[0,1]$. The results are summarized into histogram, QQ plot and Manhattan plot at below:

```{r, message=FALSE, warning=FALSE}
### Randomly generate case/control data under the null hypothesis
set.seed(123)
case <- rbinom(nrow(G),size = 1,prob = 0.3)
obj.bigSNP$fam$case <- case


### Testing for main effects using Logistic regression:
obj.gwas <- big_univLogReg(G, y01.train = case,
                           ncores = 6L, maxiter = 100)


### QQ plot, Manhattan plot and Genomic Control
snp_qq(gwas = obj.gwas)
snp_manhattan(gwas = obj.gwas, infos.chr = CHR, infos.pos = POS)

### Histogram of p-values:
p_vals <- 2*pnorm(-abs(obj.gwas$score))
hist(p_vals, breaks = 30)

```


Based on the plots above, we can conclude that p-value's distribution is very close to the uniform distribution, which is what we expect.



\clearpage

\textbf{Proposed Method: Assuming additive effect}

Then, we will apply our proposed methodology for detection of missing interaction, assuming the true effect of gene is additive. Again, we expect to see the distribution of p-values to be close to uniform.



```{r}
load("D:/gwas-practice/additive_testing.Rdata")

## View of the result
head(result_P1)

## QQ plot of p-values
qq(na.omit(result_P1$P))

## Manhattan plot of p-values:
manhattan(na.omit(result_P1))

## Histogram of p-values:
hist(result_P1$P, breaks = 30)



```








