---
title: "**A note on combining evidence from different GWAS studies for binary traits**"
author: "Ziang Zhang, Lei Sun"
output: 
  pdf_document:
    keep_tex: true
    number_sections: true
    fig_caption: yes
indent: true
header-includes:
  - \usepackage{setspace}\doublespacing
  - \usepackage{amsmath,amsthm, amssymb}
bibliographystyle: apalike
bibliography: GWAS-pvalues-ref.bibtex
---

```{r setup, include=FALSE}
library(stats)
library(tidyverse)
library(kableExtra)

knitr::opts_chunk$set(echo = TRUE, dev = 'png', message = F, warning = F)
```

\newcommand{\p}{\text{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}



# Introduction:

For most human traits, genetic effects from specific SNP only have small effect sizes [@meta2]. Therefore, practitioners often aggregate the GWAS results from different studies through meta-analysis or mega-analysis in order to achieve higher power. Aggregation through p-values is a commonly used example of meta-analysis method. For example when there are several different datasets, practitioners sometimes will first carry out a comprehensive study using one dataset, and only follow up with the SNPs that have the highest significance levels [@meta1]. Another example would be multi-trait analysis which contains a joint analysis of multiple related traits, in order to boost the statistical power [@MTAG]. In this note, we would like to consider some problems that practitioners may encounter when applying such procedures on the analysis of binary traits.

With examples of Wald test, we presented the phenomenon that the same hypothesis test on different binary traits can have very different distributions of p-value under the alternative hypothesis, hence very different powers, even if the two traits have the same true SNP effect and are analyzed using the same dataset. The same conclusion will still hold if the practitioner uses likelihood ratio test or score test, and we choose to focus on Wald test in this note because of its computational convenience.

In the next section, we will give a brief overview of Wald test for Generalized Linear Models, with a short explanation of the rationale behind the phenomenon we mentioned above. Then, we will follow with two simulation studies to illustrate how this phenomenon is affecting the analysis of binary trait, but not the analysis of continuous trait.

# Wald test for Generalized Linear Models:

Assume the generalized linear model (glm) has the following form: $$\E(Y|X) = \mu = g^{-1}(\beta_0 + \beta_G G + \beta_E E) = g^{-1}(\eta),$$ where $g(.)$ is a specific link function connecting the linear predictor $\eta$ with the mean function of $Y$. The design matrix $X$ has rows $\{(1,G_i,E_i)_{i=1}^n\}$, where $n$ is the sample size and the first column of 1 is for the intercept $\beta_0$. For the simplicity of notations, we will use $\beta=(\beta_0,\beta_G,\beta_E)^T$ to denote both the vector of all regression parameters and the vector of their true values.

In this case, the fisher information matrix at $\beta$ can be written as $$I_n(\beta) = X^TW(\beta) X,$$ where $W(\beta)$ is a diagonal matrix with each diagonal term depending on the value of $\beta$ unless $g$ is identity function. Specifically, the $i^{th}$ diagonal term of W can be computed as $$w_i=(\frac{\partial u_i}{\partial\eta_i})^2/\Var(Y_i|X).$$

If the question of interest is to test the hypothesis $H_0: \beta_G=0$ using Wald test, the test statistic can be written as $$Z = \frac{\hat{\beta}_G}{\sqrt{I_n^{-1}(\hat{\beta})_{[3,3]}}},$$ where $I_n^{-1}(\hat{\beta})_{[3,3]}$ denotes the third diagonal term of the matrix $I_n^{-1}(\hat{\beta})$ and $\hat{\beta}$ is the MLE estimate. Under the null hypothesis, $Z^2$ asymptotically follows a Chi-Square distribution with 1 degree of freedom. 

Under the alternative hypothesis that $\beta_G  \neq 0$, the non-centrality parameter of the squared Wald test statistics above can be computed as $$\frac{\beta_G^2}{I_n^{-1}(\beta)_{[3,3]}}.$$ Since $I_n^{-1}(\beta)_{[3,3]}$ will not solely depend on $\beta_G$ unless $g$ is identity. Therefore the power function of this Wald test will not only depend on $\beta_G$, but the whole vector $\beta$.

More specifically, let $d=-\frac{\beta_G}{\sqrt{I_n^{-1}(\beta)_{[3,3]}}}$, then the theoretical power of this Wald test at $\beta$ can be computed as $$1-\Phi(d+z_{a/2})+\Phi(d-z_{a/2}),$$ where $\Phi$ is the CDF of standard normal and $z_{a/2}$ is the $a/2$ quantile of standard normal.

In summary, this means that if we utilize Poisson regression to analyze count traits (e.g. number of cancers) or Logistic/Probit regression to analyze binary traits (e.g. disease status), powers of Wald test from different studies can be dramatically different, even if the two studies have the same effect size (i.e. $|\beta_G|$) and the same set of covariates $\{G_{i},E_{i}\}_{i=1}^n$. The rationale behind this is actually the classical contrast between \textbf{statistical significance} measured by p-values and \textbf{practical significance} measured by the size of the effect $|\beta_G|$. In Wald test, p-values are determined by both the practical significance $|\beta_G|$ and the standard error $\sqrt{I_n^{-1}(\beta)_{[3,3]}}$. Since the standard errors of the MLE estimator will be different on the two studies, the conclusion drawn from statistical significance may be inconsistent with the practical significance of effects in the two studies. 

# Difference between continuous trait and binary trait:

For the analysis of continuous trait, a natural option would be using ordinary Gaussian linear regression model:
$$Y = \beta_0 + \beta_G G + \beta_E E+\epsilon,$$
where $\epsilon \sim N(0,\sigma)$.

In this case, suppose the question of interest is testing $\beta_G=0$, the Wald test will have non-centrality parameter being $$\frac{\beta_G^2}{\sigma^2[X^TX]^{-1}_{[33]}}.$$

Because the (inverse) information matrix $\sigma^2[X^TX]^{-1}$ only depends on the nuisance parameter $\sigma$, power of this test will not change as $\beta_0$ or $\beta_E$ change, as long as the nuisance parameter is the same. This implies, if a SNP $G$ has true effect $\beta_G$ being constant across two traits and assume $\sigma$ being the same, then the power of testing $\beta_G = 0$ will be constant across two traits as well. Therefore, the aggregation of evidences across traits will be straightforward and smaller p value can be associated with larger SNP effect.

On the other hand, if the target is to combine evidence across several binary traits, the result will no longer be as straightforward. If traits are generated from the following logistic regression model:
$$\text{logit}(\p(Y=1|X)) = \beta_0 + \beta_G G + \beta_E E,$$
In this case, the corresponding non-centrality parameter of testing $\beta_G=0$ becomes $$\frac{\beta_G}{[X^TW_\beta X]^{-1}_{[33]}}.$$

Since $g^{-1}(\eta)= \frac{\exp(\eta)}{1+\exp(\eta)}$ for logistic regression, we can compute the $i^{th}$ term of the diagonal matrix $W_\beta$ as $$[W_\beta]_{ii} = f(\eta_i)=\frac{\exp(-\eta_i)}{(1+\exp(-\eta_i))^2}.$$
The function $f(.)$ represents the density function of standard logistic distribution, and the term $\eta_i$ is the i-th linear predictor. This implies the non-centrality parameter, hence the power will depend on every parameter in the model, not just on the parameter of interest $\beta_G$. 

To better understand the influence of $\beta_E$ on power of the Wald test for $\beta_G$. Note that $$\sigma_\eta^2:=\Var(\eta_i) = \beta_E^2\sigma_1^2+\beta_G^2\sigma_2^2 = c_1 +c_2\beta_E^2,$$ where we use $c_1$ and $c_2$ to denote constant terms that do not depend on $\beta_E$. Assume that the matrix $X^TX \approx \Sigma_X$, and $\eta_i\sim N(0,\sigma_\eta^2)$ (with density $\phi_\eta$), where $\Sigma_X$ is a matrix that does not depend on $\beta_E$. We will use the following approximation to the fisher information matrix:$$I = X^TW_\beta X \approx \mu_w \Sigma_X,$$ where $\mu_w = \E(w_i)$. Hence, we know that $$I^{-1}_{[2,2]} \propto \frac{1}{\mu_w}.$$

To compute $\mu_w$, we can approximate the standard logistic density $f(.)$ with density of $N(0,\frac{\pi}{\sqrt{3}})$ (denoted by $\phi_1$). Therefore, we have $$\mu_w = E(f(\eta_i)) \approx \int\phi_1(x)\phi_{\eta}(x)dx = \frac{1}{\sqrt{2\pi(\sigma_\eta^2+\frac{\pi^2}{3})}} \overset{approxi}{\propto} \frac{1}{|\beta_E|}.$$ Hence $I^{-1}_{[2,2]} \overset{approxi}{\propto} |\beta_E|$, which means that we expect the power of testing $\beta_G$ decreases as $|\beta_E|$ grows.

An important consequence of this phenomenon is that, the magnitude of p values (statistical significance) will not reflect the magnitude of the SNP effects (practical significance), even if the two studies are carried out on the same set of individuals. For example, if a SNP has effect $\beta_G$ on both traits, it may show significance on only one trait because of the difference in the covariate effect such as age or sex.


# Simulation with Gaussian linear regression model:

Assume a dataset of size $n=1000$ has been collected. The dataset contains the information of a continuous covariate E, a SNP G, and two continuous traits (A and B). Without loss of generality, assume this SNP follows hardy weinberg equilibrium (HWE) with minor allele frequency (MAF) $0.3$, and the covariate $E$ has been centered such that $E\sim N(0,3)$.

Furthermore, we assume that the generating models for each trait are the followings:
$$\textbf{A}:Y = -0.5 + 0.3G + 0.8E + \epsilon,$$
$$\textbf{B}: Y = -0.5 + 0.3G + 0.1E + \epsilon,$$
where the noise term $\epsilon$ follows $N(0,3)$ in both models.

To test the null hypothesis $H_0: \beta_G = 0$, a Wald test can be carried out for each trait (with $\alpha=0.05$ for simplicity). Using the formula from above, we can compute the theoretical power of each trait:

```{r continuousTraits}
### Simulated the common E and G
set.seed(100,sample.kind = "Rounding")
N <- 1000
G <- sample(c(0,1,2),size = N, replace = T, prob = c(0.49,0.42,0.09))
E <- rnorm(N,sd = 3)

### Simulate each trait's disease status based on E and G
## A:
beta0 <- -0.5
betaE <- 0.8
betaG <- 0.3
yA <- beta0 + betaG*G + betaE*E + rnorm(N,sd = 3)

## B:
beta0 <- -0.5
betaE <- 0.1
betaG <- 0.3
yB <- beta0 + betaG*G + betaE*E + rnorm(N, sd = 3)

## A:
beta0 <- -0.5
betaE <- 0.8
betaG <- 0.3
### Theoretical Power
mod_A <- lm(yA~E + G)
#### Get the design matrix:
X <- cbind(rep(1,N),mod_A$model[,-1])
### Compute the weight matrix W:
beta <- c(beta0,betaE,betaG)
I <- (1/9)* as.matrix(t(X)) %*% as.matrix(X)
#### Invert to get the true covariance matrix 
V <- solve(I)
### Compute the power function:
delta <- sqrt(1/V[3,3])*(0-beta[3])
alpha <- 0.05
Power_A <- 1- pnorm(delta - qnorm(alpha/2)) + pnorm(delta + qnorm(alpha/2))
Power_A

## B:
beta0 <- -0.5
betaE <- 0.8
betaG <- 0.3
### Theoretical Power
mod_B <- lm(yB~E + G)
#### Get the design matrix:
X <- cbind(rep(1,N),mod_B$model[,-1])
### Compute the weight matrix W:
beta <- c(beta0,betaE,betaG)
I <- (1/9)* as.matrix(t(X)) %*% as.matrix(X)
#### Invert to get the true covariance matrix 
V <- solve(I)
### Compute the power function:
delta <- sqrt(1/V[3,3])*(0-beta[3])
alpha <- 0.05
Power_B <- 1- pnorm(delta - qnorm(alpha/2)) + pnorm(delta + qnorm(alpha/2))
Power_B
```
Based on the formula from previous section, we can compute the power to be 0.549 in both studies. As we expected, since in both traits the SNP effect is the same, powers should be the same for the two traits as well. To make sure the computed theoretical powers are indeed correct, we can compare them with empirical powers obtained from repeated simulations (K = 2000):

```{r Empirical Powers Gaussian}
set.seed(12345,sample.kind = "Rounding")
## A:
beta0 <- -0.5
betaE <- 0.8
betaG <- 0.3
p1 <- c()
for (i in 1:2000) {
  yA <- beta0 + betaG*G + betaE*E + rnorm(N, sd = 3)
  mod <- lm(yA~E+G)
  p1[i] <- summary(mod)$coefficient[3,4]
}
emp_power <- mean(p1 <= alpha)
emp_power


## B:
beta0 <- -0.5
betaE <- 0.1
betaG <- 0.3
p2 <- c()
for (i in 1:2000) {
  yB <- beta0 + betaG*G + betaE*E + rnorm(N, sd = 3)
  mod <- lm(yB~E+G)
  p2[i] <- summary(mod)$coefficient[3,4]
}
emp_power <- mean(p2 <= alpha)
emp_power
```
Based on the $2000$ resampling results, the empirical powers are basically the same in the two studies (0.55 for trait A and 0.54 for trait B), which is consistent to the result from theoretical powers. 







# Simulation with logistic regression model:
Assume the same setting as before, except now the two traits of interest are both binary instead of continuous. Assume their generating models are the followings:
$$\textbf{A}:\text{logit}(\p(Y=1|G,E)) = -0.5 + 0.3G + 0.8E,$$
$$\textbf{B}: \text{logit}(\p(Y=1|G,E)) = -0.5 + 0.3G + 0.1E.$$

All the regression parameters are the same as in the example of continuous traits. A key difference between the generating model of binary traits with the one of continuous traits is that there is no nuisance parameter $\sigma$, which already implies that there might be a difference in their inferential results. All the studies are still carried out on the same set of individuals.

In this example, we consider the sampling design to be prospective for simplicity. The intercept parameter is selected to make sure the prevalence of the trait is high enough. The explicit case-control ratio for each trait is displayed at below: 

```{r simulatedData}
### Simulated the common E and G
set.seed(100,sample.kind = "Rounding")
N <- 1000
G <- sample(c(0,1,2),size = N, replace = T, prob = c(0.49,0.42,0.09))
E <- rnorm(N,sd = 3)


### Simulate each trait's disease status based on E and G
## A:
beta0 <- -0.5
betaE <- 0.8
betaG <- 0.3
ylat_A <- beta0 + betaG*G + betaE*E + rlogis(N)
y_A <- ifelse(ylat_A >=0, 1, 0)

## B:
beta0 <- -0.5
betaE <- 0.1
betaG <- 0.3
ylat_B <- beta0 + betaG*G + betaE*E + rlogis(N)
y_B <- ifelse(ylat_B >=0, 1, 0)



### Case control counts across traits:
t <- rbind(table(y_A),table(y_B)) %>% as_tibble()
rownames(t) <- c("A","B")
kableExtra::kable(t, caption = "Case Control Counts across traits") %>%
  kable_styling(latex_options = "HOLD_position", font_size = 10) 



### Case control ratio across genotypes:
t <- cbind(c(y_A,y_B),c(G,G)) %>% as_tibble()
colnames(t) <- c("Y","G")
t <- t %>% group_by(G) %>% summarise(ratio = sum(Y)/n())
kableExtra::kable(t, caption = "Case Control Ratio across genotypes") %>%
  kable_styling(latex_options = "HOLD_position", font_size = 10) 

```
We can use Wald test to test the hypothesis $\beta_G = 0$ (i.e. G is a casual SNP) for each trait:
```{r}
## A:
mod_A <- glm(y_A~E + G, family = binomial(link = "logit"))
kableExtra::kable(summary(mod_A)$coefficients, caption = "Fitted Model for Trait A") %>%
  kable_styling(latex_options = "HOLD_position", font_size = 10) 
## B:
mod_B <- glm(y_B~ E + G, family = binomial(link = "logit"))
kableExtra::kable(summary(mod_B)$coefficients, caption = "Fitted Model for Trait B") %>%
  kable_styling(latex_options = "HOLD_position", font_size = 10) 
```
Note that the p-values are $0.015$ for trait A, and $0.009$ for trait B. It is typically expected that for the trait with smaller p-value, the magnitude of the association (i.e. $|\beta_G|$) should be larger. However, in this simulation example the true value of $\beta_G$ is $\beta_G=0.3$ for both traits, and even the covariates are exactly the same. 

Again, assume that the hypothesis $\beta_G = 0$ will be tested using Wald test with $\alpha=0.05$, then we can compute the theoretical powers of the two Wald test using the simulated data $\{G_i,E_i\}_n$ and the true parameters vectors:

```{r Theoretical Powers}
## A:
beta0 <- -0.5
betaE <- 0.8
betaG <- 0.3
### Theoretical Power
mod_A <- glm(y_A~E + G, family = binomial(link = "logit"))
#### Get the design matrix:
X <- cbind(rep(1,N),mod_A$model[,-1])
### Compute the weight matrix W:
beta <- c(beta0,betaE,betaG)
#beta <- as.numeric(mod_A$coefficients)
w <- c()
for (i in 1:N) {
  si <- as.numeric(as.numeric(X[i,]) %*% beta)
  w[i] <- dlogis(si)
}
I <- as.matrix(t(X)) %*% diag(w,nrow = N,ncol = N) %*% as.matrix(X)
#### Invert to get the true covariance matrix 
V <- solve(I)
### Compute the power function:
delta <- sqrt(1/V[3,3])*(0-beta[3])
alpha <- 0.05
Power_A <- 1- pnorm(delta - qnorm(alpha/2)) + pnorm(delta + qnorm(alpha/2))
Power_A


## B:
beta0 <- -0.5
betaE <- 0.1
betaG <- 0.3
### Theoretical Power
mod_B <- glm(y_B~ E + G, family = binomial(link = "logit"))
#### Get the design matrix:
X <- cbind(rep(1,N),mod_B$model[,-1])
### Compute the weight matrix W:
beta <- c(beta0,betaE,betaG)
#beta <- as.numeric(mod_B$coefficients)
w <- c()
for (i in 1:N) {
  si <- as.numeric(as.numeric(X[i,]) %*% beta)
  w[i] <- dlogis(si)
}
I <- as.matrix(t(X)) %*% diag(w,nrow = N,ncol = N) %*% as.matrix(X)
#### Invert to get the true covariance matrix 
V <- solve(I)
### Compute the power function:
delta <- sqrt(1/V[3,3])*(0-beta[3])
alpha <- 0.05
Power_B <- 1- pnorm(delta - qnorm(alpha/2)) + pnorm(delta + qnorm(alpha/2))
Power_B
```

Based on the results above, we know in this simulation study, the power of Wald test will be $0.619$ for the trait A, and $0.861$ for the trait B. Note that Wald test on trait B has quite larger power compared to on trait A, despite the fact that the two samples are generated with same $\beta_G = 0.3$ and generated by the same set of $\{G_i,E_i\}_n$. This suggests the p-values of Wald test may have very different distributions on the two traits. We can double check that our theoretical powers for both tests are correct using empirical powers:

To compute the empirical powers, we re-simulated each type of binary trait for $K = 2000$ times, and compute the $2000$ p-values in each trait:
```{r Empirical Powers}
set.seed(100,sample.kind = "Rounding")
## A:
beta0 <- -0.5
betaE <- 0.8
betaG <- 0.3
p1 <- c()
for (i in 1:2000) {
  ylat_A <- beta0 + betaG*G + betaE*E + rlogis(N)
  y_A_rep <- ifelse(ylat_A >=0, 1, 0)
  mod <- glm(y_A_rep~E+G, family = binomial(link = "logit"))
  p1[i] <- summary(mod)$coefficient[3,4]
}
emp_power <- mean(p1 <= alpha)
emp_power

## B:
beta0 <- -0.5
betaE <- 0.1
betaG <- 0.3
p2 <- c()
for (i in 1:2000) {
  ylat_B <- beta0 + betaG*G + betaE*E + rlogis(N)
  y_B_rep <- ifelse(ylat_B >=0, 1, 0)
  mod <- glm(y_B_rep~E+G, family = binomial(link = "logit"))
  p2[i] <- summary(mod)$coefficient[3,4]
}
emp_power <- mean(p2 <= alpha)
emp_power
```
Based on the $2000$ resampling results, the empirical powers are respectively 0.612 for trait A and 0.864 for trait B. These values are quite close to the theoretical values $0.619$ and $0.861$ we computed above. The distributions of p-values in each trait can be visualized as well:

```{r visualization}
### Comparison:
pcomp <- tibble(P = c(p1,p2), trait = c(rep("A",2000),rep("B",2000)))
pcomp %>% ggplot(aes(x = P, fill = trait)) + geom_histogram(bins = 20, alpha=0.5, position="identity")
```

Based on the figure above, we can conclude that the distribution of p values in trait B is stochastically smaller than the distribution in trait A, even if their underlying $\beta_G$ are both $0.3$. Therefore, it shows that the magnitudes of p-values of different studies are not directly comparable, unless the generalized linear regression model being used is the ordinary linear regression model with $g$ being identity function.


\clearpage


# Bibliography
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\noindent
